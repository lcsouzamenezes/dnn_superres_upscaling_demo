{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e4d9a2d",
   "metadata": {},
   "source": [
    "# Upscaling video with Python OpenCV\n",
    "\n",
    "(C) 2021 Seb Sikora, published under the [MIT License](https://opensource.org/licenses/MIT)\n",
    "\n",
    "[seb.nf.sikora@protonmail.com](mailto:seb.nf.sikora@protonmail.com)\n",
    "***\n",
    "<br/>\n",
    "\n",
    "## Get using deep-learning based methods in your own Python projects with<br/>OpenCV dnn_superres\n",
    "<br/>\n",
    "\n",
    "[Super Resolution (SR)](https://blog.paperspace.com/image-super-resolution/) image upscaling via deep-learning based approaches can acheive really impressive performance compared to naive methods.\n",
    "\n",
    "It's really easy to leverage this power in your own projects using the [OpenCV dnn_superres module](https://docs.opencv.org/4.x/d5/d29/tutorial_dnn_superres_upscale_image_single.html), all you need to get started is to install the [OpenCV-contrib modules](https://pypi.org/project/opencv-contrib-python/) and download a [pre-trained](https://github.com/Saafke/FSRCNN_Tensorflow/tree/master/models)[ model](https://github.com/Saafke/EDSR_Tensorflow/tree/master/models). \n",
    "\n",
    "Xavier Weber has a great walk-through of the process of installing the modules and upscaling a single image [here](https://towardsdatascience.com/deep-learning-based-super-resolution-with-opencv-4fd736678066).\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "Below, I'm going to run-through how to apply the same approach to upscaling video files.\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1608a05d",
   "metadata": {},
   "source": [
    "## Upscaling a video file in Python using dnn_superres\n",
    "<br/>\n",
    "\n",
    "Using some of the other features of OpenCV, we can use the same techniques demonstrated above to upscale video files! \n",
    "\n",
    "To demonstrate this, let's start with some gorgeous freely available videos provided by [Ajaya Bist](https://www.pexels.com/video/close-up-view-of-a-parrot-4982608/) and [Erkan AvanoÄŸlu](https://www.pexels.com/video/little-bird-inside-a-house-5761115/) over at [pexels.com](https://www.pexels.com/)\n",
    "\n",
    "The original video dimensions are 1280x720, so first using ffmpeg we'll downscale both videos to 200x112 as shown at 100% scaling below. We will only retain the first ten seconds of the videos for the purpose of this demonstration.\n",
    "\n",
    "```\n",
    "user@home:~/dnn_superres/ffmpeg -t 10 -i video_1_1280x720.mp4 -vf scale=200:-2 -preset slow -crf 18 video_1_200x112.mp4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "08285669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "    <td><video width=\"100%\" controls>\n",
       "        <source src=\"videos/original/video_1_200x112.mp4\" type=\"video/mp4\">\n",
       "    </video></td>\n",
       "    <td><video width=\"100%\" controls>\n",
       "        <source src=\"videos/original/video_2_200x112.mp4\" type=\"video/mp4\">\n",
       "    </video></td>\n",
       "</tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<table>\n",
    "<tr>\n",
    "    <td><video width=\"100%\" controls>\n",
    "        <source src=\"videos/original/video_1_200x112.mp4\" type=\"video/mp4\">\n",
    "    </video></td>\n",
    "    <td><video width=\"100%\" controls>\n",
    "        <source src=\"videos/original/video_2_200x112.mp4\" type=\"video/mp4\">\n",
    "    </video></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8144f5f",
   "metadata": {},
   "source": [
    "Now let's take a look at the code!\n",
    "\n",
    "We're going to be using the OpenCV [VideoCapture](https://docs.opencv.org/4.5.4/d8/dfe/classcv_1_1VideoCapture.html#ac4107fb146a762454a8a87715d9b7c96) class to open our low-res source video and iterate through it frame-by-frame, the OpenCV contrib [dnn_superres interface](https://docs.opencv.org/4.x/d5/d29/tutorial_dnn_superres_upscale_image_single.html) to upscale each frame, and the OpenCV [VideoWriter](https://docs.opencv.org/4.5.4/dd/d9e/classcv_1_1VideoWriter.html#ac3478f6257454209fa99249cc03a5c59) class to create an output container and fill it with our upscaled frames.\n",
    "\n",
    "Lastly, we will [use ffmpeg](https://superuser.com/questions/277642/how-to-merge-audio-and-video-file-in-ffmpeg) to mux the upscaled output video with the audio from the low-res source video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "bf3f806a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 1/250 processed.\n",
      "Frame 2/250 processed.\n",
      "Frame 3/250 processed.\n",
      "Frame 4/250 processed.\n",
      "Frame 5/250 processed.\n",
      "Frame 6/250 processed.\n",
      "Frame 7/250 processed.\n",
      "Frame 8/250 processed.\n",
      "Frame 9/250 processed.\n",
      "Frame 10/250 processed.\n",
      "Frame 11/250 processed.\n",
      "Frame 12/250 processed.\n",
      "Frame 13/250 processed.\n",
      "Frame 14/250 processed.\n",
      "Frame 15/250 processed.\n",
      "Frame 16/250 processed.\n",
      "Frame 17/250 processed.\n",
      "Frame 18/250 processed.\n",
      "Frame 19/250 processed.\n",
      "Frame 20/250 processed.\n",
      "Frame 21/250 processed.\n",
      "Frame 22/250 processed.\n",
      "Frame 23/250 processed.\n",
      "Frame 24/250 processed.\n",
      "Frame 25/250 processed.\n",
      "Frame 26/250 processed.\n",
      "Frame 27/250 processed.\n",
      "Frame 28/250 processed.\n",
      "Frame 29/250 processed.\n",
      "Frame 30/250 processed.\n",
      "Frame 31/250 processed.\n",
      "Frame 32/250 processed.\n",
      "Frame 33/250 processed.\n",
      "Frame 34/250 processed.\n",
      "Frame 35/250 processed.\n",
      "Frame 36/250 processed.\n",
      "Frame 37/250 processed.\n",
      "Frame 38/250 processed.\n",
      "Frame 39/250 processed.\n",
      "Frame 40/250 processed.\n",
      "Frame 41/250 processed.\n",
      "Frame 42/250 processed.\n",
      "Frame 43/250 processed.\n",
      "Frame 44/250 processed.\n",
      "Frame 45/250 processed.\n",
      "Frame 46/250 processed.\n",
      "Frame 47/250 processed.\n",
      "Frame 48/250 processed.\n",
      "Frame 49/250 processed.\n",
      "Frame 50/250 processed.\n",
      "Frame 51/250 processed.\n",
      "Frame 52/250 processed.\n",
      "Frame 53/250 processed.\n",
      "Frame 54/250 processed.\n",
      "Frame 55/250 processed.\n",
      "Frame 56/250 processed.\n",
      "Frame 57/250 processed.\n",
      "Frame 58/250 processed.\n",
      "Frame 59/250 processed.\n",
      "Frame 60/250 processed.\n",
      "Frame 61/250 processed.\n",
      "Frame 62/250 processed.\n",
      "Frame 63/250 processed.\n",
      "Frame 64/250 processed.\n",
      "Frame 65/250 processed.\n",
      "Frame 66/250 processed.\n",
      "Frame 67/250 processed.\n",
      "Frame 68/250 processed.\n",
      "Frame 69/250 processed.\n",
      "Frame 70/250 processed.\n",
      "Frame 71/250 processed.\n",
      "Frame 72/250 processed.\n",
      "Frame 73/250 processed.\n",
      "Frame 74/250 processed.\n",
      "Frame 75/250 processed.\n",
      "Frame 76/250 processed.\n",
      "Frame 77/250 processed.\n",
      "Frame 78/250 processed.\n",
      "Frame 79/250 processed.\n",
      "Frame 80/250 processed.\n",
      "Frame 81/250 processed.\n",
      "Frame 82/250 processed.\n",
      "Frame 83/250 processed.\n",
      "Frame 84/250 processed.\n",
      "Frame 85/250 processed.\n",
      "Frame 86/250 processed.\n",
      "Frame 87/250 processed.\n",
      "Frame 88/250 processed.\n",
      "Frame 89/250 processed.\n",
      "Frame 90/250 processed.\n",
      "Frame 91/250 processed.\n",
      "Frame 92/250 processed.\n",
      "Frame 93/250 processed.\n",
      "Frame 94/250 processed.\n",
      "Frame 95/250 processed.\n",
      "Frame 96/250 processed.\n",
      "Frame 97/250 processed.\n",
      "Frame 98/250 processed.\n",
      "Frame 99/250 processed.\n",
      "Frame 100/250 processed.\n",
      "Frame 101/250 processed.\n",
      "Frame 102/250 processed.\n",
      "Frame 103/250 processed.\n",
      "Frame 104/250 processed.\n",
      "Frame 105/250 processed.\n",
      "Frame 106/250 processed.\n",
      "Frame 107/250 processed.\n",
      "Frame 108/250 processed.\n",
      "Frame 109/250 processed.\n",
      "Frame 110/250 processed.\n",
      "Frame 111/250 processed.\n",
      "Frame 112/250 processed.\n",
      "Frame 113/250 processed.\n",
      "Frame 114/250 processed.\n",
      "Frame 115/250 processed.\n",
      "Frame 116/250 processed.\n",
      "Frame 117/250 processed.\n",
      "Frame 118/250 processed.\n",
      "Frame 119/250 processed.\n",
      "Frame 120/250 processed.\n",
      "Frame 121/250 processed.\n",
      "Frame 122/250 processed.\n",
      "Frame 123/250 processed.\n",
      "Frame 124/250 processed.\n",
      "Frame 125/250 processed.\n",
      "Frame 126/250 processed.\n",
      "Frame 127/250 processed.\n",
      "Frame 128/250 processed.\n",
      "Frame 129/250 processed.\n",
      "Frame 130/250 processed.\n",
      "Frame 131/250 processed.\n",
      "Frame 132/250 processed.\n",
      "Frame 133/250 processed.\n",
      "Frame 134/250 processed.\n",
      "Frame 135/250 processed.\n",
      "Frame 136/250 processed.\n",
      "Frame 137/250 processed.\n",
      "Frame 138/250 processed.\n",
      "Frame 139/250 processed.\n",
      "Frame 140/250 processed.\n",
      "Frame 141/250 processed.\n",
      "Frame 142/250 processed.\n",
      "Frame 143/250 processed.\n",
      "Frame 144/250 processed.\n",
      "Frame 145/250 processed.\n",
      "Frame 146/250 processed.\n",
      "Frame 147/250 processed.\n",
      "Frame 148/250 processed.\n",
      "Frame 149/250 processed.\n",
      "Frame 150/250 processed.\n",
      "Frame 151/250 processed.\n",
      "Frame 152/250 processed.\n",
      "Frame 153/250 processed.\n",
      "Frame 154/250 processed.\n",
      "Frame 155/250 processed.\n",
      "Frame 156/250 processed.\n",
      "Frame 157/250 processed.\n",
      "Frame 158/250 processed.\n",
      "Frame 159/250 processed.\n",
      "Frame 160/250 processed.\n",
      "Frame 161/250 processed.\n",
      "Frame 162/250 processed.\n",
      "Frame 163/250 processed.\n",
      "Frame 164/250 processed.\n",
      "Frame 165/250 processed.\n",
      "Frame 166/250 processed.\n",
      "Frame 167/250 processed.\n",
      "Frame 168/250 processed.\n",
      "Frame 169/250 processed.\n",
      "Frame 170/250 processed.\n",
      "Frame 171/250 processed.\n",
      "Frame 172/250 processed.\n",
      "Frame 173/250 processed.\n",
      "Frame 174/250 processed.\n",
      "Frame 175/250 processed.\n",
      "Frame 176/250 processed.\n",
      "Frame 177/250 processed.\n",
      "Frame 178/250 processed.\n",
      "Frame 179/250 processed.\n",
      "Frame 180/250 processed.\n",
      "Frame 181/250 processed.\n",
      "Frame 182/250 processed.\n",
      "Frame 183/250 processed.\n",
      "Frame 184/250 processed.\n",
      "Frame 185/250 processed.\n",
      "Frame 186/250 processed.\n",
      "Frame 187/250 processed.\n",
      "Frame 188/250 processed.\n",
      "Frame 189/250 processed.\n",
      "Frame 190/250 processed.\n",
      "Frame 191/250 processed.\n",
      "Frame 192/250 processed.\n",
      "Frame 193/250 processed.\n",
      "Frame 194/250 processed.\n",
      "Frame 195/250 processed.\n",
      "Frame 196/250 processed.\n",
      "Frame 197/250 processed.\n",
      "Frame 198/250 processed.\n",
      "Frame 199/250 processed.\n",
      "Frame 200/250 processed.\n",
      "Frame 201/250 processed.\n",
      "Frame 202/250 processed.\n",
      "Frame 203/250 processed.\n",
      "Frame 204/250 processed.\n",
      "Frame 205/250 processed.\n",
      "Frame 206/250 processed.\n",
      "Frame 207/250 processed.\n",
      "Frame 208/250 processed.\n",
      "Frame 209/250 processed.\n",
      "Frame 210/250 processed.\n",
      "Frame 211/250 processed.\n",
      "Frame 212/250 processed.\n",
      "Frame 213/250 processed.\n",
      "Frame 214/250 processed.\n",
      "Frame 215/250 processed.\n",
      "Frame 216/250 processed.\n",
      "Frame 217/250 processed.\n",
      "Frame 218/250 processed.\n",
      "Frame 219/250 processed.\n",
      "Frame 220/250 processed.\n",
      "Frame 221/250 processed.\n",
      "Frame 222/250 processed.\n",
      "Frame 223/250 processed.\n",
      "Frame 224/250 processed.\n",
      "Frame 225/250 processed.\n",
      "Frame 226/250 processed.\n",
      "Frame 227/250 processed.\n",
      "Frame 228/250 processed.\n",
      "Frame 229/250 processed.\n",
      "Frame 230/250 processed.\n",
      "Frame 231/250 processed.\n",
      "Frame 232/250 processed.\n",
      "Frame 233/250 processed.\n",
      "Frame 234/250 processed.\n",
      "Frame 235/250 processed.\n",
      "Frame 236/250 processed.\n",
      "Frame 237/250 processed.\n",
      "Frame 238/250 processed.\n",
      "Frame 239/250 processed.\n",
      "Frame 240/250 processed.\n",
      "Frame 241/250 processed.\n",
      "Frame 242/250 processed.\n",
      "Frame 243/250 processed.\n",
      "Frame 244/250 processed.\n",
      "Frame 245/250 processed.\n",
      "Frame 246/250 processed.\n",
      "Frame 247/250 processed.\n",
      "Frame 248/250 processed.\n",
      "Frame 249/250 processed.\n",
      "Frame 250/250 processed.\n",
      "Mux-ing audio...\n"
     ]
    }
   ],
   "source": [
    "import cv2                                                # VideoCapture, VideoWriter, resize\n",
    "from cv2 import dnn_superres                              # dnn_superres interface\n",
    "import subprocess                                         # Needed to run ffmpeg to mux old audio & new video...\n",
    "import os                                                 # ...(see at the end below)\n",
    "\n",
    "scale_factor = 4   # Set upscaling factor here\n",
    "\n",
    "in_file = './videos/original/video_1_200x112.mp4'        # Path to input video file (low res)\n",
    "temp_file = in_file[:-4] + '_temp.mp4'                    # Path to temporary output video file (no audio)\n",
    "out_file = in_file[:-4] + '_final.mp4'                    # Path to final output video file (with audio)\n",
    "\n",
    "# ------ dnn_superres setup -------------------------------\n",
    "# (no different from upscaling a single image)\n",
    "# Create an SR object\n",
    "sr = dnn_superres.DnnSuperResImpl_create()\n",
    "\n",
    "# Read the desired pre-trained model\n",
    "sr.readModel(\"./pre-trained-models/FSRCNN_x4.pb\")\n",
    "# (For details and pre-trained models see\n",
    "# https://github.com/opencv/opencv_contrib/tree/master/modules/dnn_superres#models)\n",
    "\n",
    "# Set the desired model and scale to get correct pre- and post-processing\n",
    "# Other options for first argument \"edsr\", \"espcn\", \"lapsrn\"\n",
    "sr.setModel(\"fsrcnn\", scale_factor)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Create videocapture object with the path to the input video file as argument\n",
    "cap = cv2.VideoCapture(in_file)\n",
    "\n",
    "# Determine the video framerate, length in frames, frame height and width\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) * scale_factor    # Appropriately scale the height\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) * scale_factor      # and width for the upscaled output video\n",
    "\n",
    "# Create a VideoWriter object that we will use to create the temporary output video file\n",
    "# If we installed OpenCV via eg pip, H264 encoding is not included (https://stackoverflow.com/a/55598602)\n",
    "# If we want the final upscaled output in H264 format we need to convert after-the-fact using ffmpeg\n",
    "# Here we will use mp4v format for now\n",
    "out = cv2.VideoWriter(temp_file, cv2.VideoWriter_fourcc('m','p','4','v'), fps, (width, height))\n",
    "\n",
    "# Now we run the upscaling loop one frame-by-frame\n",
    "i = 0\n",
    "while cap.isOpened():\n",
    "    status, frame = cap.read()    # Read the 'next frame' from the input video file\n",
    "    \n",
    "    if not status:                # If we have reached the end of the input video file stop the loop\n",
    "        break\n",
    "    \n",
    "    result = sr.upsample(frame)   # Upscale the frame, just like upscaling a single image\n",
    "    \n",
    "    out.write(result)             # Write the upscaled frame to the temporary output video file\n",
    "    \n",
    "    # It can take a *long* time so nice to have some indication of progress\n",
    "    i += 1\n",
    "    print('Frame ' + str(i) + '/' + str(total_frames) + ' processed.')\n",
    "\n",
    "# Close the input and temporary output video files\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# Using our upscaled frames, we have built an output video file, but it doesn't have any audio!\n",
    "# We can use ffmpeg (again!) to create a final output file by muxing together the newly created\n",
    "# temporary output file and the audio from the original input file.\n",
    "print('Mux-ing audio...')\n",
    "\n",
    "# Construct the cli command (info on doing this here - https://superuser.com/questions/277642/how-to-merge-audio-and-video-file-in-ffmpeg)\n",
    "command = \"ffmpeg -i {temp_file} -i {in_file} -c copy -map 0:v:0 -map 1:a:0 -shortest {out_file}\".format(temp_file = temp_file, in_file = in_file, out_file = out_file)\n",
    "\n",
    "# Run the command\n",
    "subprocess.call(command,shell=True)\n",
    "\n",
    "# Tidy up by removing the temporary output file\n",
    "os.remove(temp_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b0a9a4",
   "metadata": {},
   "source": [
    "We'll also create some counter-examples upscaled via more-traditional approaches.\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "First we can use the same code as above, modified to use the OpenCV [resize](https://docs.opencv.org/4.5.4/da/d54/group__imgproc__transform.html#ga47a974309e9102f5f08231edc7e7529d) function to upscale each frame, by default via linear interpolation. \n",
    "\n",
    "```python\n",
    "# We use the same code as above, but we substitute this\n",
    "\n",
    "result = cv2.resize(frame, (frame.shape[1] * scale_factor, frame.shape[0] * scale_factor))\n",
    "\n",
    "# In place of this\n",
    "\n",
    "result = sr.upsample(frame)\n",
    "```\n",
    "<br/>\n",
    "\n",
    "Lastly we can use [ffmpeg](https://write.corbpie.com/a-guide-to-upscaling-or-downscaling-video-with-ffmpeg/), which by default uses bicubic interpolation.\n",
    "\n",
    "```\n",
    "user@home:~/dnn_superres/ffmpeg -i video_1_200x112.mp4 -vf scale=800:-2 -preset slow -crf 18 video_1_200x112_ffmpeg_x4.mp4\n",
    "```\n",
    "<br/>\n",
    "\n",
    "So, to recap: We will upscale both videos x4 to 800x450 via the approaches outlined above and compare:\n",
    "* cv2.resize (linear interpolation)\n",
    "* ffmpeg (bicubic interpolation)\n",
    "* dnn_superres with the FSRCNN model\n",
    "* dnn_superres with the EDSR model\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "(Note - For the embedded videos within this notebook to play to play correctly on my workstation I had to pass them through ffmpeg again to losslessly convert from mp4v to x264 eg `ffmpeg -i video_1_ffmpeg_ds_800x450.mp4 -c:v libx264 video_1_ffmpeg_ds_800x450_x264.mp4 \n",
    "`)\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "Let's take a look at the results for video_1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "3211570d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"100%\" controls>\n",
       "  <source src=\"videos/upsampled/video_1_200x112_cv2_resize_x4_x264.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"100%\" controls>\n",
    "  <source src=\"videos/upsampled/video_1_200x112_cv2_resize_x4_x264.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e2296202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"100%\" controls>\n",
       "  <source src=\"videos/upsampled/video_1_200x112_ffmpeg_x4.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"100%\" controls>\n",
    "  <source src=\"videos/upsampled/video_1_200x112_ffmpeg_x4.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f038a2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"100%\" controls>\n",
       "  <source src=\"videos/upsampled/video_1_200x112_FSRCNN_x4_x264.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"100%\" controls>\n",
    "  <source src=\"videos/upsampled/video_1_200x112_FSRCNN_x4_x264.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "fe7a001b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"100%\" controls>\n",
       "  <source src=\"videos/upsampled/video_1_200x112_EDSR_x4_x264.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"100%\" controls>\n",
    "  <source src=\"videos/upsampled/video_1_200x112_EDSR_x4_x264.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e15002b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"100%\" controls>\n",
       "  <source src=\"videos/original/video_1_ffmpeg_ds_800x450.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"100%\" controls>\n",
    "  <source src=\"videos/original/video_1_ffmpeg_ds_800x450.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6cf26a",
   "metadata": {},
   "source": [
    "And for video_2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "7325f3a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"100%\" controls>\n",
       "  <source src=\"videos/upsampled/video_2_200x112_cv2_resize_x4_x264.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"100%\" controls>\n",
    "  <source src=\"videos/upsampled/video_2_200x112_cv2_resize_x4_x264.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "190b23a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"100%\" controls>\n",
       "  <source src=\"videos/upsampled/video_2_200x112_ffmpeg_x4.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"100%\" controls>\n",
    "  <source src=\"videos/upsampled/video_2_200x112_ffmpeg_x4.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "f9814da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"100%\" controls>\n",
       "  <source src=\"videos/upsampled/video_2_200x112_FSRCNN_x4_x264.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"100%\" controls>\n",
    "  <source src=\"videos/upsampled/video_2_200x112_FSRCNN_x4_x264.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "fcc907ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"100%\" controls>\n",
       "  <source src=\"videos/upsampled/video_2_200x112_EDSR_x4_x264.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"100%\" controls>\n",
    "  <source src=\"videos/upsampled/video_2_200x112_EDSR_x4_x264.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1b4bf0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"100%\" controls>\n",
       "  <source src=\"videos/original/video_2_ffmpeg_ds_800x450.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"100%\" controls>\n",
    "  <source src=\"videos/original/video_2_ffmpeg_ds_800x450.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc5271b",
   "metadata": {},
   "source": [
    "Blah blah blah..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64772352",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c667d333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"100%\" controls>\n",
       "  <source src=\"videos/upsampled/video_1_200x112_cv2_resize_x8_x264.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"100%\" controls>\n",
    "  <source src=\"videos/upsampled/video_1_200x112_cv2_resize_x8_x264.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "294120c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"100%\" controls>\n",
       "  <source src=\"videos/upsampled/video_1_200x112_LapSRN_x8_x264.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"100%\" controls>\n",
    "  <source src=\"videos/upsampled/video_1_200x112_LapSRN_x8_x264.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "9e93f1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"100%\" controls>\n",
       "  <source src=\"videos/upsampled/video_2_200x112_cv2_resize_x8_x264.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"100%\" controls>\n",
    "  <source src=\"videos/upsampled/video_2_200x112_cv2_resize_x8_x264.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2f93c615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"100%\" controls>\n",
       "  <source src=\"videos/upsampled/video_2_200x112_LapSRN_x8_x264.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"100%\" controls>\n",
    "  <source src=\"videos/upsampled/video_2_200x112_LapSRN_x8_x264.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57931bc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
